## Project of Team Celeste in Google AI ML Winter Camp Shanghai
14 - 18 January, 2019

Team Members: Minjun Li & Shaoxiang Chen, Fudan University

This project wins the final **Best Project Award**. Many thanks to Google and TensorflowðŸŒž!

### Introduction
We first explored training different models to recognize sketches in the Quick Draw dataset. We found that a hand-crafted CNN can be trained in a short time and achieve reasonable accuracy. 
With a trained CNN, we are able to perform various interesting tasks, such as: **inter-class similarity analysis**, **CNN class activation map visualization for interpretability**, **definitive stroke analysis and visualization**, and finally, to **hint the players of Quick Draw** with our CNN and Sketch RNN. Technics from papers[1,2] are used in our work. 

[Slides](https://drive.google.com/file/d/1C3Z2w02fp16IHedLa7EsprKt8JuVorvW/view?usp=sharing) (demo videos inside!) and [Poster](https://docs.google.com/presentation/d/1ZVL8tNfcQwmrQDrjD7xsQrK2Wicy3xOxWTGXVyQEUHI/edit?usp=sharing) are available in Google Drive.

### About the Code

```
.   
â”œâ”€â”€ cluster                             # clustering analysis
â”‚Â Â  â”œâ”€â”€ analysis.ipynb                      # notebook for inter-class similarity analysis
â”‚Â Â  â”œâ”€â”€ class_id_map.pkl                    # file containing class label --> id mapping
â”‚Â Â  â”œâ”€â”€ extract_feature.py                  # script to extract features of validation images from trained CNN
â”‚Â Â  â”œâ”€â”€ tsne_cls100.png                     # image of t-SNE visualization of CNN features
â”‚Â Â  â”œâ”€â”€ tsne.ipynb                          # notebook for t-SNE visualization
â”‚Â Â  â””â”€â”€ tsne.png                            # image of t-SNE visualization of CNN features
â”œâ”€â”€ common                              # common files and codes used by other scripts
â”‚Â Â  â”œâ”€â”€ class_id_map.pkl                    # file containing class label --> id mapping   
â”‚Â Â  â”œâ”€â”€ fixed_model.py                      # final CNN model for sketch recognition
â”‚Â Â  â”œâ”€â”€ model.py                            # contains various CNN models we tried
â”‚Â Â  â”œâ”€â”€ preprocessing                       # preprocessing styles for different networks
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cifarnet_preprocessing.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ inception_preprocessing.py          # we only use inception style
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ lenet_preprocessing.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ preprocessing_factory.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ vgg_preprocessing.py
â”‚Â Â  â””â”€â”€ utils.py                            # utility functions
â”œâ”€â”€ infer                               # things to do after having a trained CNN model
â”‚Â Â  â”œâ”€â”€ bee.png                             # sample image containing a 'bee'
â”‚Â Â  â”œâ”€â”€ best_stroke.ipynb                   # definitive stroke analysis
â”‚Â Â  â”œâ”€â”€ ckpt                                # tensorflow model checkpoints
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ classifier                          # CNN classifier
â”‚Â Â  â”‚Â Â  â””â”€â”€ flamingo                            # sketch RNN
â”‚Â Â  â”œâ”€â”€ class_id_map.pkl
â”‚Â Â  â”œâ”€â”€ feat_extraction.ipynb               # extracts feature & original strokes for definitive stroke analysis
â”‚Â Â  â”œâ”€â”€ infer.py                            # inference utility of CNN, providing image --> class API and supports local and network mode
â”‚Â Â  â”œâ”€â”€ infer_rnn.py                        # inference utility of sketch RNN
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ sketch_ai_play.py                   # attempt to make sketch RNN play by itself
â”‚Â Â  â”œâ”€â”€ sketch_cli.py                       # Quick Draw GUI that connects to an inference server for definitive stroke hints
â”‚Â Â  â”œâ”€â”€ sketch_no_hint.py                   # Quick Draw GUI without any hint
â”‚Â Â  â””â”€â”€ sketch.py                           # Quick Draw GUI that gets hint from skecth RNN
â”œâ”€â”€ legacy                              # legacy train & val code
â”‚Â Â  â”œâ”€â”€ train.ipynb
â”‚Â Â  â””â”€â”€ val.ipynb
â”œâ”€â”€ LICENSE
â”œâ”€â”€ mkdata                              # make training data
â”‚Â Â  â”œâ”€â”€ class_id_map.pkl
â”‚Â Â  â””â”€â”€ mkdata.ipynb                        # convert raw strokes into images and save as tfrecord
â”œâ”€â”€ README.md
â””â”€â”€ trainval                            # final train & validation scripts
    â”œâ”€â”€ cnn                                 # hand-crafted CNN
    â”‚Â Â  â”œâ”€â”€ cnn_vis.ipynb                       # notebook for CNN class activation map visualization
    â”‚Â Â  â”œâ”€â”€ gp_model.py                         # CNN model with global pooling for visualization
    â”‚Â Â  â”œâ”€â”€ log
    â”‚Â Â  â”œâ”€â”€ train.py                            # training script
    â”‚Â Â  â””â”€â”€ val.py                              # validation script
    â””â”€â”€ rnn                                 # rnn from official tensorflow tutorial
        â”œâ”€â”€ create_dataset.py                   # save raw strokes to tfrecord
        â””â”€â”€ train.py                            # training & validation script
```

### Model Training

We trained RNN and CNN to recognize sketches. While RNN can achieve higher accuracy, it needs a long time to train. So we hand-crafted a shallow CNN instead, and it reaches reasonable perormance in a short time.
<div align="center">
  <img src="https://raw.githubusercontent.com/forwchen/celeste/master/pics/rnn%26cnn.png" height="256">
</div>

For training CNNs, we draw the strokes in images and resize them to 128x128. The CNN is trained with batch size 512, Adam optimizer with learning rate 0.001 and 100000 iterations. All our analysis is based on the trained CNN. 

### Inter-Class Similarity Analysis  
IPython Notebook [here](https://github.com/forwchen/celeste/blob/master/cluster/analysis.ipynb).

To see if the CNN feature from the 'FC 512' layers captures inter-class similarity, we first do a t-SNE visualization.
<div align="center">
  <img src="https://raw.githubusercontent.com/forwchen/celeste/master/pics/t-sne_merge.png">
</div>

There are classes that form dense clusters as visualized, but some others scatter all over the space, which inidicates they could be very similar to other classes. 
To find out the confusing classes, we sort the 340 classes by their similarity to all other classes in descending order. The top ones are:
<div align="center">
  <img src="https://raw.githubusercontent.com/forwchen/celeste/master/pics/similarity_top.png" height="200">
</div>

These classes all have very simple shape that is close to a rectangle. 
See the full list [here](https://github.com/forwchen/celeste/blob/master/pics/class_similarity_heatmap.png). 

For each class, the most similar class to them can be found [here](https://github.com/forwchen/celeste/blob/master/pics/most_similar.png). And some samples here.
<div align="center">
  <img src="https://raw.githubusercontent.com/forwchen/celeste/master/pics/similar_pair.png" height="200">
</div>

### CNN Class Activation Map Visualization for Interpretability  
IPython Notebook [here](https://github.com/forwchen/celeste/blob/master/trainval/cnn/cnn_vis.ipynb).

To understand why the CNN made such predictions, we use the technic from [1] to compute a CNN activation map for visualizing contributions from each spatial region. Below are samples for 'cookie', 'hospital' and 'cell phone'.
<div align="center">
  <img src="https://raw.githubusercontent.com/forwchen/celeste/master/pics/cnn_activation_map.png" height="300">
</div>



### Definitive Stroke Analysis and Visualization  
IPython Notebook [here](https://github.com/forwchen/celeste/blob/master/infer/best_stroke.ipynb).


#### References
[1] Zhou, Bolei, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. "Learning deep features for discriminative localization." CVPR 2016.

[2] Ha, David, and Douglas Eck. "A neural representation of sketch drawings."Â ICLR 2018.
